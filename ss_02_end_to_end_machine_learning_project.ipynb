{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Main'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "'''Data Viz'''\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "import matplotlib as mpl\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "'''Data Prep'''\n",
    "from sklearn import preprocessing as pp \n",
    "from scipy.stats import pearsonr \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "from sklearn.metrics import log_loss \n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score \n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report \n",
    "\n",
    "'''Algos'''\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acquire Data\n",
    "current_path = os.getcwd()\n",
    "# file = '\\\\datasets\\\\credit_card_data\\\\credit_card.csv'\n",
    "file = '/datasets/credit_card_data/creditcard.csv'\n",
    "data = pd.read_csv(current_path + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore Data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of fraudulent transactions:\", data['Class'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nanCounter = np.isnan(data).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nanCounter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinctCounter = data.apply(lambda x: len(x.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinctCounter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate feature matrix and labels array\n",
    "dataX = data.copy().drop(['Class'],axis=1)\n",
    "dataY = data['Class'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "featuresToScale = dataX.drop(['Time'],axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresToScale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scott fit_transform http://bit.ly/2VszQHC\n",
    "sX = pp.StandardScaler(copy=True)\n",
    "dataX.loc[:,featuresToScale] = sX.fit_transform(dataX[featuresToScale])\n",
    "scalingFactors = pd.DataFrame(data=[sX.mean_,sX.scale_],index=['Mean','StDev'],columns=featuresToScale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalingFactors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataX.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### start scott\n",
    "* [scaling](https://scikit-learn.org/stable/modules/preprocessing.html)\n",
    "* [formula](http://bit.ly/2VsNLxo)\n",
    "* [latex syntax](http://bit.ly/2Vqm8oJ)\n",
    "* [quick basic ref](http://bit.ly/2VsRoU2)\n",
    "* `z value` $$ z  = \\frac{x - \\mu}{\\sigma} $$\n",
    "* `mean` $$ \\mu = \\frac{1}{N} \\sum_{i=1}^{N} (x_i) $$\n",
    "* `standard deviation` $$ \\sigma = \\sqrt{\\frac{1}{N} \\sum_{i=1}^{N}(x_i - \\mu)^2} $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([[ 1., -1.,  2.],\n",
    "...                     [ 2.,  0.,  0.],\n",
    "...                     [ 0.,  1., -1.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = pp.scale(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[np.mean([1.,2.,0.]), np.std([1.,2.,0.])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for second row, first column \n",
    "xs = (2-1)/0.816496580927726\n",
    "xs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### end scott"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlationMatrix = pd.DataFrame(data=[],index=dataX.columns,columns=dataX.columns)\n",
    "for i in dataX.columns:\n",
    "    for j in dataX.columns:\n",
    "        correlationMatrix.loc[i,j] = np.round(pearsonr(dataX.loc[:,i],dataX.loc[:,j])[0],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlationMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_file = '/datasets/credit_card_datacorrelationMatrix.csv'\n",
    "correlationMatrix.to_csv(current_path+correlation_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_classes = pd.value_counts(data['Class'],sort=True).sort_index()\n",
    "ax = sns.barplot(x=count_classes.index, y=tuple(count_classes/len(data)))\n",
    "ax.set_title('Frequency Percentage by Class')\n",
    "ax.set_xlabel('Class')\n",
    "ax.set_ylabel('Frequency Percentage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p39\n",
    "# scott stratify: https://en.wikipedia.org/wiki/Stratified_sampling\n",
    "# cross entropy: http://bit.ly/2Vtr5Ns\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataX, \n",
    "                                    dataY, test_size=0.33, \n",
    "                                    random_state=2018, stratify=dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.sum()/len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.sum()/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scott http://bit.ly/2VsHJwI\n",
    "k_fold = StratifiedKFold(n_splits=5,shuffle=True,random_state=2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set hyperparameters\n",
    "# l1 & l2 http://bit.ly/2VqDTUR\n",
    "penalty = 'l2'\n",
    "C = 1.0\n",
    "class_weight = 'balanced'\n",
    "random_state = 2018\n",
    "solver = 'liblinear'\n",
    "n_jobs = 1\n",
    "\n",
    "# http://bit.ly/2VzoZeY\n",
    "logReg = LogisticRegression(penalty=penalty, C=C, \n",
    "            class_weight=class_weight, random_state=random_state, \n",
    "                            solver=solver, n_jobs=n_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### start scott"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataX.shape[0]*0.67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingScores = []\n",
    "cvScores = []\n",
    "# y_train is 67% of total data set\n",
    "# all predictions of training set, across all folds\n",
    "predictionsBasedOnKFolds = pd.DataFrame(data=[],\n",
    "                                        index=y_train.index,columns=[0,1])\n",
    "predictionsBasedOnKFolds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### end scott"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingScores = []\n",
    "cvScores = []\n",
    "predictionsBasedOnKFolds = pd.DataFrame(data=[],\n",
    "                                        index=y_train.index,columns=[0,1])\n",
    "\n",
    "model = logReg\n",
    "\n",
    "for train_index, cv_index in k_fold.split(np.zeros(len(X_train))\n",
    "                                          ,y_train.ravel()):\n",
    "    X_train_fold, X_cv_fold = X_train.iloc[train_index,:], \\\n",
    "        X_train.iloc[cv_index,:]\n",
    "    y_train_fold, y_cv_fold = y_train.iloc[train_index], \\\n",
    "        y_train.iloc[cv_index]\n",
    "    \n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "    loglossTraining = log_loss(y_train_fold, \n",
    "                               model.predict_proba(X_train_fold)[:,1])\n",
    "    trainingScores.append(loglossTraining)\n",
    "    \n",
    "    predictionsBasedOnKFolds.loc[X_cv_fold.index,:] = \\\n",
    "        model.predict_proba(X_cv_fold)  \n",
    "    loglossCV = log_loss(y_cv_fold, \n",
    "                         predictionsBasedOnKFolds.loc[X_cv_fold.index,1])\n",
    "    cvScores.append(loglossCV)\n",
    "    \n",
    "    print('Training Log Loss: ', loglossTraining)\n",
    "    print('CV Log Loss: ', loglossCV)\n",
    "    \n",
    "loglossLogisticRegression = log_loss(y_train, \n",
    "                                     predictionsBasedOnKFolds.loc[:,1])\n",
    "print('Logistic Regression Log Loss: ', loglossLogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.concat([y_train,predictionsBasedOnKFolds.loc[:,1]], axis=1)\n",
    "preds.columns = ['trueLabel','prediction']\n",
    "predictionsBasedOnKFoldsLogisticRegression = preds.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(preds['trueLabel'],\n",
    "                                                       preds['prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_precision = average_precision_score(preds['trueLabel'],\n",
    "                                            preds['prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.step(recall, precision, color='k', alpha=0.7, where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.3, color='k')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "\n",
    "plt.title('Precision-Recall curve: Average Precision = {0:0.2f}'.format(\n",
    "          average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(preds['trueLabel'],preds['prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "areaUnderROC = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='r', lw=2, label='ROC curve')\n",
    "plt.plot([0, 1], [0, 1], color='k', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic: \\\n",
    "          Area under the curve = {0:0.2f}'.format(areaUnderROC))\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 10\n",
    "max_features = 'auto'\n",
    "max_depth = None\n",
    "min_samples_split = 2\n",
    "min_samples_leaf = 1\n",
    "min_weight_fraction_leaf = 0.0\n",
    "max_leaf_nodes = None\n",
    "bootstrap = True\n",
    "oob_score = False\n",
    "n_jobs = -1\n",
    "random_state = 2018\n",
    "class_weight = 'balanced'\n",
    "\n",
    "RFC = RandomForestClassifier(n_estimators=n_estimators, \n",
    "        max_features=max_features, max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf,\n",
    "        min_weight_fraction_leaf=min_weight_fraction_leaf, \n",
    "        max_leaf_nodes=max_leaf_nodes, bootstrap=bootstrap, \n",
    "        oob_score=oob_score, n_jobs=n_jobs, random_state=random_state, \n",
    "        class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingScores = []\n",
    "cvScores = []\n",
    "predictionsBasedOnKFolds = pd.DataFrame(data=[],\n",
    "                                        index=y_train.index,columns=[0,1])\n",
    "\n",
    "model = RFC\n",
    "\n",
    "for train_index, cv_index in k_fold.split(np.zeros(len(X_train)),\n",
    "                                          y_train.ravel()):\n",
    "    X_train_fold, X_cv_fold = X_train.iloc[train_index,:], \\\n",
    "        X_train.iloc[cv_index,:]\n",
    "    y_train_fold, y_cv_fold = y_train.iloc[train_index], \\\n",
    "        y_train.iloc[cv_index]\n",
    "    \n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "    loglossTraining = log_loss(y_train_fold, \\\n",
    "                                model.predict_proba(X_train_fold)[:,1])\n",
    "    trainingScores.append(loglossTraining)\n",
    "    \n",
    "    predictionsBasedOnKFolds.loc[X_cv_fold.index,:] = \\\n",
    "        model.predict_proba(X_cv_fold)  \n",
    "    loglossCV = log_loss(y_cv_fold, \\\n",
    "        predictionsBasedOnKFolds.loc[X_cv_fold.index,1])\n",
    "    cvScores.append(loglossCV)\n",
    "    \n",
    "    print('Training Log Loss: ', loglossTraining)\n",
    "    print('CV Log Loss: ', loglossCV)\n",
    "    \n",
    "loglossRandomForestsClassifier = log_loss(y_train, \n",
    "                                          predictionsBasedOnKFolds.loc[:,1])\n",
    "print('Random Forests Log Loss: ', loglossRandomForestsClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.concat([y_train,predictionsBasedOnKFolds.loc[:,1]], axis=1)\n",
    "preds.columns = ['trueLabel','prediction']\n",
    "predictionsBasedOnKFoldsRandomForests = preds.copy()\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(preds['trueLabel'],\n",
    "                                                       preds['prediction'])\n",
    "average_precision = average_precision_score(preds['trueLabel'],\n",
    "                                            preds['prediction'])\n",
    "\n",
    "plt.step(recall, precision, color='k', alpha=0.7, where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.3, color='k')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "\n",
    "plt.title('Precision-Recall curve: Average Precision = {0:0.2f}'.format(\n",
    "          average_precision))\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(preds['trueLabel'],preds['prediction'])\n",
    "areaUnderROC = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='r', lw=2, label='ROC curve')\n",
    "plt.plot([0, 1], [0, 1], color='k', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic: \\\n",
    "          Area under the curve = {0:0.2f}'.format(\n",
    "          areaUnderROC))\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_xGB = {\n",
    "    'nthread':16, #number of cores\n",
    "    'learning rate': 0.3, #range 0 to 1, default 0.3\n",
    "    'gamma': 0, #range 0 to infinity, default 0 \n",
    "        # increase to reduce complexity (increase bias, reduce variance)\n",
    "    'max_depth': 6, #range 1 to infinity, default 6\n",
    "    'min_child_weight': 1, #range 0 to infinity, default 1\n",
    "    'max_delta_step': 0, #range 0 to infinity, default 0\n",
    "    'subsample': 1.0, #range 0 to 1, default 1\n",
    "        # subsample ratio of the training examples\n",
    "    'colsample_bytree': 1.0, #range 0 to 1, default 1 \n",
    "        # subsample ratio of features\n",
    "    'objective':'binary:logistic',\n",
    "    'num_class':1,\n",
    "    'eval_metric':'logloss',\n",
    "    'seed':2018,\n",
    "    'silent':1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingScores = []\n",
    "cvScores = []\n",
    "predictionsBasedOnKFolds = pd.DataFrame(data=[],\n",
    "                                    index=y_train.index,columns=['prediction'])\n",
    "\n",
    "for train_index, cv_index in k_fold.split(np.zeros(len(X_train)),\n",
    "                                          y_train.ravel()):\n",
    "    X_train_fold, X_cv_fold = X_train.iloc[train_index,:], \\\n",
    "        X_train.iloc[cv_index,:]\n",
    "    y_train_fold, y_cv_fold = y_train.iloc[train_index], \\\n",
    "        y_train.iloc[cv_index]\n",
    "    \n",
    "    dtrain = xgb.DMatrix(data=X_train_fold, label=y_train_fold)\n",
    "    dCV = xgb.DMatrix(data=X_cv_fold)\n",
    "    \n",
    "    bst = xgb.cv(params_xGB, dtrain, num_boost_round=2000, \n",
    "                 nfold=5, early_stopping_rounds=200, verbose_eval=50)\n",
    "    \n",
    "    best_rounds = np.argmin(bst['test-logloss-mean'])\n",
    "    bst = xgb.train(params_xGB, dtrain, best_rounds)\n",
    "    \n",
    "    loglossTraining = log_loss(y_train_fold, bst.predict(dtrain))\n",
    "    trainingScores.append(loglossTraining)\n",
    "    \n",
    "    predictionsBasedOnKFolds.loc[X_cv_fold.index,'prediction'] = \\\n",
    "        bst.predict(dCV)\n",
    "    loglossCV = log_loss(y_cv_fold, \\\n",
    "        predictionsBasedOnKFolds.loc[X_cv_fold.index,'prediction'])\n",
    "    cvScores.append(loglossCV)\n",
    "    \n",
    "    print('Training Log Loss: ', loglossTraining)\n",
    "    print('CV Log Loss: ', loglossCV)\n",
    "    \n",
    "loglossXGBoostGradientBoosting = \\\n",
    "    log_loss(y_train, predictionsBasedOnKFolds.loc[:,'prediction'])\n",
    "print('XGBoost Gradient Boosting Log Loss: ', loglossXGBoostGradientBoosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.concat([y_train,predictionsBasedOnKFolds.loc[:,'prediction']], axis=1)\n",
    "preds.columns = ['trueLabel','prediction']\n",
    "predictionsBasedOnKFoldsXGBoostGradientBoosting = preds.copy()\n",
    "\n",
    "precision, recall, thresholds = \\\n",
    "    precision_recall_curve(preds['trueLabel'],preds['prediction'])\n",
    "average_precision = \\\n",
    "    average_precision_score(preds['trueLabel'],preds['prediction'])\n",
    "\n",
    "plt.step(recall, precision, color='k', alpha=0.7, where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.3, color='k')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "\n",
    "plt.title('Precision-Recall curve: Average Precision = {0:0.2f}'.format(\n",
    "          average_precision))\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(preds['trueLabel'],preds['prediction'])\n",
    "areaUnderROC = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='r', lw=2, label='ROC curve')\n",
    "plt.plot([0, 1], [0, 1], color='k', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic: \\\n",
    "        Area under the curve = {0:0.2f}'.format(areaUnderROC))\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_lightGB = {\n",
    "    'task': 'train',\n",
    "    'application':'binary',\n",
    "    'num_class':1,\n",
    "    'boosting': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'metric_freq':50,\n",
    "    'is_training_metric':False,\n",
    "    'max_depth':4,\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.01,\n",
    "    'feature_fraction': 1.0,\n",
    "    'bagging_fraction': 1.0,\n",
    "    'bagging_freq': 0,\n",
    "    'bagging_seed': 2018,\n",
    "    'verbose': 0,\n",
    "    'num_threads':16\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingScores = []\n",
    "cvScores = []\n",
    "predictionsBasedOnKFolds = pd.DataFrame(data=[],\n",
    "                                index=y_train.index,columns=['prediction'])\n",
    "\n",
    "for train_index, cv_index in k_fold.split(np.zeros(len(X_train)),\n",
    "                                          y_train.ravel()):\n",
    "    X_train_fold, X_cv_fold = X_train.iloc[train_index,:], \\\n",
    "        X_train.iloc[cv_index,:]\n",
    "    y_train_fold, y_cv_fold = y_train.iloc[train_index], \\\n",
    "        y_train.iloc[cv_index]\n",
    "    \n",
    "    lgb_train = lgb.Dataset(X_train_fold, y_train_fold)\n",
    "    lgb_eval = lgb.Dataset(X_cv_fold, y_cv_fold, reference=lgb_train)\n",
    "    gbm = lgb.train(params_lightGB, lgb_train, num_boost_round=2000,\n",
    "                   valid_sets=lgb_eval, early_stopping_rounds=200)\n",
    "    \n",
    "    loglossTraining = log_loss(y_train_fold, \\\n",
    "                gbm.predict(X_train_fold, num_iteration=gbm.best_iteration))\n",
    "    trainingScores.append(loglossTraining)\n",
    "    \n",
    "    predictionsBasedOnKFolds.loc[X_cv_fold.index,'prediction'] = \\\n",
    "        gbm.predict(X_cv_fold, num_iteration=gbm.best_iteration) \n",
    "    loglossCV = log_loss(y_cv_fold, \\\n",
    "        predictionsBasedOnKFolds.loc[X_cv_fold.index,'prediction'])\n",
    "    cvScores.append(loglossCV)\n",
    "    \n",
    "    print('Training Log Loss: ', loglossTraining)\n",
    "    print('CV Log Loss: ', loglossCV)\n",
    "    \n",
    "loglossLightGBMGradientBoosting = \\\n",
    "    log_loss(y_train, predictionsBasedOnKFolds.loc[:,'prediction'])\n",
    "print('LightGBM Gradient Boosting Log Loss: ', loglossLightGBMGradientBoosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.concat([y_train,predictionsBasedOnKFolds.loc[:,'prediction']], axis=1)\n",
    "preds.columns = ['trueLabel','prediction']\n",
    "predictionsBasedOnKFoldsLightGBMGradientBoosting = preds.copy()\n",
    "\n",
    "precision, recall, thresholds = \\\n",
    "    precision_recall_curve(preds['trueLabel'],preds['prediction'])\n",
    "average_precision = \\\n",
    "    average_precision_score(preds['trueLabel'],preds['prediction'])\n",
    "\n",
    "plt.step(recall, precision, color='k', alpha=0.7, where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.3, color='k')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "\n",
    "plt.title('Precision-Recall curve: Average Precision = {0:0.2f}'.format(\n",
    "          average_precision))\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(preds['trueLabel'],preds['prediction'])\n",
    "areaUnderROC = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='r', lw=2, label='ROC curve')\n",
    "plt.plot([0, 1], [0, 1], color='k', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic: \\\n",
    "Area under the curve = {0:0.2f}'.format(areaUnderROC))\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsTestSetLogisticRegression = \\\n",
    "    pd.DataFrame(data=[],index=y_test.index,columns=['prediction'])\n",
    "predictionsTestSetLogisticRegression.loc[:,'prediction'] = \\\n",
    "    logReg.predict_proba(X_test)[:,1]\n",
    "logLossTestSetLogisticRegression = \\\n",
    "    log_loss(y_test, predictionsTestSetLogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsTestSetRandomForests = \\\n",
    "    pd.DataFrame(data=[],index=y_test.index,columns=['prediction'])\n",
    "predictionsTestSetRandomForests.loc[:,'prediction'] = \\\n",
    "    RFC.predict_proba(X_test)[:,1]\n",
    "logLossTestSetRandomForests = \\\n",
    "    log_loss(y_test, predictionsTestSetRandomForests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsTestSetXGBoostGradientBoosting = \\\n",
    "    pd.DataFrame(data=[],index=y_test.index,columns=['prediction'])\n",
    "dtest = xgb.DMatrix(data=X_test)\n",
    "predictionsTestSetXGBoostGradientBoosting.loc[:,'prediction'] = \\\n",
    "    bst.predict(dtest)\n",
    "logLossTestSetXGBoostGradientBoosting = \\\n",
    "    log_loss(y_test, predictionsTestSetXGBoostGradientBoosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsTestSetLightGBMGradientBoosting = \\\n",
    "    pd.DataFrame(data=[],index=y_test.index,columns=['prediction'])\n",
    "predictionsTestSetLightGBMGradientBoosting.loc[:,'prediction'] = \\\n",
    "    gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "logLossTestSetLightGBMGradientBoosting = \\\n",
    "    log_loss(y_test, predictionsTestSetLightGBMGradientBoosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Log Loss of Logistic Regression on Test Set: \", \\\n",
    "          logLossTestSetLogisticRegression)\n",
    "print(\"Log Loss of Random Forests on Test Set: \", \\\n",
    "          logLossTestSetRandomForests)\n",
    "print(\"Log Loss of XGBoost Gradient Boosting on Test Set: \", \\\n",
    "          logLossTestSetXGBoostGradientBoosting)\n",
    "print(\"Log Loss of LightGBM Gradient Boosting on Test Set: \", \\\n",
    "          logLossTestSetLightGBMGradientBoosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresholds = \\\n",
    "    precision_recall_curve(y_test,predictionsTestSetLogisticRegression)\n",
    "average_precision = \\\n",
    "    average_precision_score(y_test,predictionsTestSetLogisticRegression)\n",
    "\n",
    "plt.step(recall, precision, color='k', alpha=0.7, where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.3, color='k')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "\n",
    "plt.title('Precision-Recall curve: Average Precision = {0:0.2f}'.format(\n",
    "          average_precision))\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test,predictionsTestSetLogisticRegression)\n",
    "areaUnderROC = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='r', lw=2, label='ROC curve')\n",
    "plt.plot([0, 1], [0, 1], color='k', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic: \\\n",
    "Area under the curve = {0:0.2f}'.format(areaUnderROC))\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresholds = \\\n",
    "    precision_recall_curve(y_test,predictionsTestSetRandomForests)\n",
    "average_precision = \\\n",
    "    average_precision_score(y_test,predictionsTestSetRandomForests)\n",
    "\n",
    "plt.step(recall, precision, color='k', alpha=0.7, where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.3, color='k')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "\n",
    "plt.title('Precision-Recall curve: Average Precision = {0:0.2f}'.format(\n",
    "          average_precision))\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test,predictionsTestSetRandomForests)\n",
    "areaUnderROC = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='r', lw=2, label='ROC curve')\n",
    "plt.plot([0, 1], [0, 1], color='k', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic: \\\n",
    "Area under the curve = {0:0.2f}'.format(areaUnderROC))\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresholds = \\\n",
    "    precision_recall_curve(y_test,predictionsTestSetXGBoostGradientBoosting)\n",
    "average_precision = \\\n",
    "    average_precision_score(y_test,predictionsTestSetXGBoostGradientBoosting)\n",
    "\n",
    "plt.step(recall, precision, color='k', alpha=0.7, where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.3, color='k')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "\n",
    "plt.title('Precision-Recall curve: Average Precision = {0:0.2f}'.format(\n",
    "          average_precision))\n",
    "\n",
    "fpr, tpr, thresholds = \\\n",
    "    roc_curve(y_test,predictionsTestSetXGBoostGradientBoosting)\n",
    "areaUnderROC = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='r', lw=2, label='ROC curve')\n",
    "plt.plot([0, 1], [0, 1], color='k', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic: \\\n",
    "Area under the curve = {0:0.2f}'.format(areaUnderROC))\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresholds = \\\n",
    "    precision_recall_curve(y_test,predictionsTestSetLightGBMGradientBoosting)\n",
    "average_precision = \\\n",
    "    average_precision_score(y_test,predictionsTestSetLightGBMGradientBoosting)\n",
    "\n",
    "plt.step(recall, precision, color='k', alpha=0.7, where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.3, color='k')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "\n",
    "plt.title('Precision-Recall curve: Average Precision = {0:0.2f}'.format(\n",
    "          average_precision))\n",
    "\n",
    "fpr, tpr, thresholds = \\\n",
    "    roc_curve(y_test,predictionsTestSetLightGBMGradientBoosting)\n",
    "areaUnderROC = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='r', lw=2, label='ROC curve')\n",
    "plt.plot([0, 1], [0, 1], color='k', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic: \\\n",
    "Area under the curve = {0:0.2f}'.format(areaUnderROC))\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsBasedOnKFoldsFourModels = pd.DataFrame(data=[],index=y_train.index)\n",
    "predictionsBasedOnKFoldsFourModels = predictionsBasedOnKFoldsFourModels.join(\n",
    "    predictionsBasedOnKFoldsLogisticRegression['prediction'].astype(float), \\\n",
    "    how='left').join(predictionsBasedOnKFoldsRandomForests['prediction'] \\\n",
    "    .astype(float),how='left',rsuffix=\"2\").join( \\\n",
    "    predictionsBasedOnKFoldsXGBoostGradientBoosting['prediction'].astype(float), \\\n",
    "    how='left',rsuffix=\"3\").join( \\\n",
    "    predictionsBasedOnKFoldsLightGBMGradientBoosting['prediction'].astype(float), \\\n",
    "    how='left',rsuffix=\"4\")\n",
    "predictionsBasedOnKFoldsFourModels.columns = \\\n",
    "    ['predsLR','predsRF','predsXGB','predsLightGBM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainWithPredictions = \\\n",
    "    X_train.merge(predictionsBasedOnKFoldsFourModels,\n",
    "                  left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_lightGB = {\n",
    "    'task': 'train',\n",
    "    'application':'binary',\n",
    "    'num_class':1,\n",
    "    'boosting': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'metric_freq':50,\n",
    "    'is_training_metric':False,\n",
    "    'max_depth':4,\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.01,\n",
    "    'feature_fraction': 1.0,\n",
    "    'bagging_fraction': 1.0,\n",
    "    'bagging_freq': 0,\n",
    "    'bagging_seed': 2018,\n",
    "    'verbose': 0,\n",
    "    'num_threads':16\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingScores = []\n",
    "cvScores = []\n",
    "predictionsBasedOnKFoldsEnsemble = \\\n",
    "    pd.DataFrame(data=[],index=y_train.index,columns=['prediction'])\n",
    "\n",
    "for train_index, cv_index in k_fold.split(np.zeros(len(X_train)), \\\n",
    "                                          y_train.ravel()):\n",
    "    X_train_fold, X_cv_fold = \\\n",
    "        X_trainWithPredictions.iloc[train_index,:], \\\n",
    "        X_trainWithPredictions.iloc[cv_index,:]\n",
    "    y_train_fold, y_cv_fold = y_train.iloc[train_index], y_train.iloc[cv_index]\n",
    "    \n",
    "    lgb_train = lgb.Dataset(X_train_fold, y_train_fold)\n",
    "    lgb_eval = lgb.Dataset(X_cv_fold, y_cv_fold, reference=lgb_train)\n",
    "    gbm = lgb.train(params_lightGB, lgb_train, num_boost_round=2000,\n",
    "                   valid_sets=lgb_eval, early_stopping_rounds=200)\n",
    "    \n",
    "    loglossTraining = log_loss(y_train_fold, \\\n",
    "        gbm.predict(X_train_fold, num_iteration=gbm.best_iteration))\n",
    "    trainingScores.append(loglossTraining)\n",
    "    \n",
    "    predictionsBasedOnKFoldsEnsemble.loc[X_cv_fold.index,'prediction'] = \\\n",
    "        gbm.predict(X_cv_fold, num_iteration=gbm.best_iteration) \n",
    "    loglossCV = log_loss(y_cv_fold, \\\n",
    "        predictionsBasedOnKFoldsEnsemble.loc[X_cv_fold.index,'prediction'])\n",
    "    cvScores.append(loglossCV)\n",
    "    \n",
    "    print('Training Log Loss: ', loglossTraining)\n",
    "    print('CV Log Loss: ', loglossCV)\n",
    "    \n",
    "loglossEnsemble = log_loss(y_train, \\\n",
    "        predictionsBasedOnKFoldsEnsemble.loc[:,'prediction'])\n",
    "print('Ensemble Log Loss: ', loglossEnsemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Feature importances:', list(gbm.feature_importance()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.concat([y_train,predictionsBasedOnKFoldsEnsemble.loc[:,'prediction']], axis=1)\n",
    "preds.columns = ['trueLabel','prediction']\n",
    "\n",
    "precision, recall, thresholds = \\\n",
    "    precision_recall_curve(preds['trueLabel'],preds['prediction'])\n",
    "average_precision = \\\n",
    "    average_precision_score(preds['trueLabel'],preds['prediction'])\n",
    "\n",
    "plt.step(recall, precision, color='k', alpha=0.7, where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.3, color='k')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "\n",
    "plt.title('Precision-Recall curve: Average Precision = {0:0.2f}'.format(\n",
    "          average_precision))\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(preds['trueLabel'],preds['prediction'])\n",
    "areaUnderROC = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='r', lw=2, label='ROC curve')\n",
    "plt.plot([0, 1], [0, 1], color='k', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic: \\\n",
    "Area under the curve = {0:0.2f}'.format(areaUnderROC))\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatterData = predictionsTestSetLightGBMGradientBoosting.join(y_test,how='left')\n",
    "scatterData.columns = ['Predicted Probability','True Label']\n",
    "ax = sns.regplot(x=\"True Label\", y=\"Predicted Probability\", color='k', \n",
    "                 fit_reg=False, scatter_kws={'alpha':0.1},\n",
    "                 data=scatterData).set_title( \\\n",
    "                'Plot of Prediction Probabilities and the True Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatterDataMelted = pd.melt(scatterData, \"True Label\", \\\n",
    "                            var_name=\"Predicted Probability\")\n",
    "ax = sns.stripplot(x=\"value\", y=\"Predicted Probability\", \\\n",
    "                   hue='True Label', jitter=0.4, \\\n",
    "                   data=scatterDataMelted).set_title( \\\n",
    "                   'Plot of Prediction Probabilities and the True Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Pipeline for New Data'''\n",
    "# first, import new data into a dataframe called 'newData'\n",
    "# second, scale data\n",
    "# newData.loc[:,featuresToScale] = sX.transform(newData[featuresToScale])\n",
    "# third, predict using LightGBM\n",
    "# gbm.predict(newData, num_iteration=gbm.best_iteration)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
